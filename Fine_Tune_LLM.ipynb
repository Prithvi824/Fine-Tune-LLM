{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bf46fdf9b1c47648b764fac1457bdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ac47ca55c24299b846af267a414f7f",
              "IPY_MODEL_07b8f6ddf7ec41d687ff1eaa21922f99",
              "IPY_MODEL_cc7331e63cfb423996e2e24eecae81c2"
            ],
            "layout": "IPY_MODEL_355e0e8d74504ee7bdd7a5d21255c58a"
          }
        },
        "41ac47ca55c24299b846af267a414f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75368223d926439096211f8def884b41",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3ca04b39ae1f40c78ba6ce1947ab15b0",
            "value": "Map:â€‡100%"
          }
        },
        "07b8f6ddf7ec41d687ff1eaa21922f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f4d17add7049d3bbf5081cf2ca05be",
            "max": 638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d913adca3e744a51841faae68d6c1817",
            "value": 638
          }
        },
        "cc7331e63cfb423996e2e24eecae81c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd38fe2c4c9451aa431c99ffd46a6eb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e240987862484a2bbd12dc06b689bc10",
            "value": "â€‡638/638â€‡[00:00&lt;00:00,â€‡2772.28â€‡examples/s]"
          }
        },
        "355e0e8d74504ee7bdd7a5d21255c58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75368223d926439096211f8def884b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca04b39ae1f40c78ba6ce1947ab15b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f4d17add7049d3bbf5081cf2ca05be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d913adca3e744a51841faae68d6c1817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfd38fe2c4c9451aa431c99ffd46a6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e240987862484a2bbd12dc06b689bc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31a934b939b4253a0db2e9ef6befad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8623019bb6045249d6b700dac5a9e51",
              "IPY_MODEL_d5cf0ef1d81b4f1bb991cbdfe20f7440",
              "IPY_MODEL_142d18915ff24f2886aeaaa754090244"
            ],
            "layout": "IPY_MODEL_1c58298deb894e3299d3270e9ed9817b"
          }
        },
        "d8623019bb6045249d6b700dac5a9e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5d1f078ad24b8797a5c43737d7c184",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72c90a51a49b4b80ab2ea6ad621cc2ac",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=6):â€‡100%"
          }
        },
        "d5cf0ef1d81b4f1bb991cbdfe20f7440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98b14d6ebe64cb99f74831b0ee2e80c",
            "max": 638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56ea28765ad8425e913d459366864c1f",
            "value": 638
          }
        },
        "142d18915ff24f2886aeaaa754090244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17adb1a90654215b6e986f39bc01532",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ce3ae0abe894c7096247706ac696a22",
            "value": "â€‡638/638â€‡[00:04&lt;00:00,â€‡266.28â€‡examples/s]"
          }
        },
        "1c58298deb894e3299d3270e9ed9817b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5d1f078ad24b8797a5c43737d7c184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c90a51a49b4b80ab2ea6ad621cc2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98b14d6ebe64cb99f74831b0ee2e80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ea28765ad8425e913d459366864c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a17adb1a90654215b6e986f39bc01532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce3ae0abe894c7096247706ac696a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRufHdLdYR2R",
        "outputId": "09fca002-6ea4-412d-f3e7-3715a22b2b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.12/dist-packages (2.11.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.11.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings) (1.2.1)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.11.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.3.0)\n",
            "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.1)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.11.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2025.11.3)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.9.35)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.0.32.post2)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.48.2)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.3->unsloth) (0.14.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.3->unsloth) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.3->unsloth) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.3->unsloth) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic pydantic-settings trl unsloth colorama\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: All the imports are done here to respect dependencies\n",
        "# 1st party imports\n",
        "import json\n",
        "from typing import Tuple, Optional, Dict\n",
        "\n",
        "# NOTE: this should be the first 3rd party module\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# 3rd party imports\n",
        "import torch\n",
        "from colorama import Fore\n",
        "from pydantic import Field\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import TrainingArguments\n",
        "from pydantic_settings import BaseSettings\n",
        "\n",
        "\n",
        "# disbale torch dynamo to be compatible with unsloth\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "torch._dynamo.config.disable = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKijIHo-ZezR",
        "outputId": "b60417d4-9714-451e-c57f-f858aac1c043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This is the settings file for the fine-tuning of the LLM.\n",
        "\"\"\"\n",
        "\n",
        "# NOTE: All the imports are done here to respect dependencies\n",
        "# # 1st party imports\n",
        "# from typing import Optional\n",
        "\n",
        "# # 3rd party imports\n",
        "# import torch\n",
        "# from pydantic import Field\n",
        "# from transformers import TrainingArguments\n",
        "# from pydantic_settings import BaseSettings\n",
        "\n",
        "\n",
        "class Settings(BaseSettings):\n",
        "    \"\"\"Configuration class for LLM fine-tuning settings.\"\"\"\n",
        "\n",
        "    # dataset settings\n",
        "    chat_file: str = Field(\n",
        "        default=\"data/transcript.csv\", description=\"Path to the transcript file.\"\n",
        "    )\n",
        "    jsonl_file: str = Field(\n",
        "        default=\"/content/drive/MyDrive/collab files/transcript_data_final.jsonl\",\n",
        "        description=\"Path to the proccessed transcript data file.\",\n",
        "    )\n",
        "    context_window: int = Field(\n",
        "        default=5,\n",
        "        description=\"Number of lines to consider for context.\",\n",
        "    )\n",
        "\n",
        "    # character settings\n",
        "    character_name: str = Field(\n",
        "        default=\"ZeroTwo\",\n",
        "        description=\"Name of the character to extract data for.\",\n",
        "    )\n",
        "\n",
        "    # model settings\n",
        "    model_name: str = Field(\n",
        "        default=\"unsloth/Qwen2-VL-7B-Instruct-unsloth-bnb-4bit\",\n",
        "        description=\"Name of the model to be fine-tuned.\",\n",
        "    )\n",
        "    max_seq_length: int = Field(default=2048, description=\"Maximum sequence length.\")\n",
        "    dtype: Optional[str] = Field(default=None, description=\"Data type.\")\n",
        "    load_in_4bit: bool = Field(default=True, description=\"Load the model in 4-bit.\")\n",
        "    dataset_text_field: str = Field(\n",
        "        default=\"text\", description=\"Text field of the dataset.\"\n",
        "    )\n",
        "    dataset_num_proc: int = Field(\n",
        "        default=4, description=\"Number of processes to use for the dataset.\"\n",
        "    )\n",
        "    assistant_only_loss: bool = Field(\n",
        "        default=True, description=\"Use assistant only loss.\"\n",
        "    )\n",
        "\n",
        "    # lora settings\n",
        "    lora_rank: int = Field(default=64, description=\"Rank of the LoRA adapter.\")\n",
        "    lora_alpha: int = Field(default=128, description=\"Alpha of the LoRA adapter.\")\n",
        "    lora_dropout: float = Field(\n",
        "        default=0.05, description=\"Dropout of the LoRA adapter.\"\n",
        "    )\n",
        "    lora_target_modules: list = Field(\n",
        "        default=[\n",
        "            \"q_proj\",\n",
        "            \"k_proj\",\n",
        "            \"v_proj\",\n",
        "            \"o_proj\",\n",
        "            \"gate_proj\",\n",
        "            \"up_proj\",\n",
        "            \"down_proj\",\n",
        "        ],\n",
        "        description=\"Target modules of the LoRA adapter.\",\n",
        "    )\n",
        "\n",
        "    # hub settings\n",
        "    push_to_hub: bool = Field(default=False, description=\"Push the model to the hub.\")\n",
        "    hf_repo_id: str = Field(\n",
        "        default=\"Prithvi00/ZeroTwo-Qwen2-VL-7B-Fine-Tune\",\n",
        "        description=\"ID of the repository to push the model to.\",\n",
        "    )\n",
        "\n",
        "    # testing settings\n",
        "    user_test_message: str = Field(\n",
        "        default=\"Do you want to ride a franxx zero two?\",\n",
        "        description=\"Test message to generate response for.\",\n",
        "    )\n",
        "    system_prompt: Optional[str] = Field(\n",
        "        default=\"You are a friendly anime character ZeroTwo from Darling in the franxx. Reply to the messages in a way that is both flirty and feels like a human being. You may get sad, angry, frustrated, depressed or feel any such emotions based on the user's message tone and content.\",\n",
        "        description=\"System prompt for the model.\",\n",
        "    )\n",
        "    max_new_tokens: int = Field(\n",
        "        default=512, description=\"Maximum number of new tokens to generate.\"\n",
        "    )\n",
        "    temperature: float = Field(default=0.25, description=\"Temperature for generation.\")\n",
        "    top_p: float = Field(default=0.1, description=\"Top P for generation.\")\n",
        "\n",
        "    # the model's training args\n",
        "    training_args: TrainingArguments = TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        gradient_checkpointing=True,\n",
        "        warmup_steps=50,\n",
        "        num_train_epochs=5,\n",
        "        learning_rate=2e-5,\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=5,\n",
        "        optim=\"adamw_torch_8bit\",\n",
        "        prediction_loss_only=True,\n",
        "        logging_strategy=\"steps\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        save_strategy=\"best\",\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        dataloader_pin_memory=True,\n",
        "        dataloader_num_workers=4,\n",
        "        max_grad_norm=1.0,\n",
        "    )\n",
        "\n",
        "\n",
        "settings = Settings()\n"
      ],
      "metadata": {
        "id": "wIMLS_ftYStI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This is the main file for the fine-tuning of the LLM.\n",
        "\"\"\"\n",
        "\n",
        "# NOTE: All the imports are done on the top to respect dependencies\n",
        "# # 1st party imports\n",
        "# import json\n",
        "# from typing import Tuple, Optional, Dict\n",
        "\n",
        "# # NOTE: this should be the first 3rd party module\n",
        "# from unsloth import FastLanguageModel\n",
        "\n",
        "# # 3rd party imports\n",
        "# import torch\n",
        "# from colorama import Fore\n",
        "# from trl import SFTTrainer\n",
        "# from datasets import load_dataset, Dataset\n",
        "# from transformers import TrainingArguments\n",
        "\n",
        "# local imports\n",
        "# from settings import settings\n",
        "\n",
        "\n",
        "def _load_data(tokenizer: FastLanguageModel, file_path: str):\n",
        "    \"\"\"\n",
        "    This function loads the data.\n",
        "    ### NOTE: This is the second step in the training process.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (FastLanguageModel): The tokenizer to use.\n",
        "        file_path (str): The path to the file to load.\n",
        "\n",
        "    Returns:\n",
        "        data: The loaded data.\n",
        "    \"\"\"\n",
        "\n",
        "    def formatting_prompts_func(example):\n",
        "        \"\"\"\n",
        "        Formats the prompts for fine-tuning the model.\n",
        "        \"\"\"\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            example[\"messages\"], tokenize=False, add_generation_prompt=False\n",
        "        )\n",
        "        return {\"text\": prompt}\n",
        "\n",
        "    return load_dataset(\"json\", data_files=file_path).map(formatting_prompts_func)\n",
        "\n",
        "\n",
        "def _load_model(\n",
        "    name: str,\n",
        "    max_seq_length: int,\n",
        "    dtype: str,\n",
        "    load_in_4bit: bool,\n",
        "    **kwargs: Optional[Dict],\n",
        ") -> Tuple[FastLanguageModel, FastLanguageModel]:\n",
        "    \"\"\"\n",
        "    This function loads the model and tokenizer.\n",
        "    ### NOTE: This is the first step in the training process.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the model.\n",
        "        max_seq_length (int): The maximum sequence length.\n",
        "        dtype (str): The data type.\n",
        "        load_in_4bit (bool): Whether to load the model in 4bit.\n",
        "        **kwargs (Optional[Dict]): Additional keyword arguments.\n",
        "\n",
        "    Returns:\n",
        "        model: The loaded model.\n",
        "        tokenizer: The loaded tokenizer.\n",
        "    \"\"\"\n",
        "    return FastLanguageModel.from_pretrained(\n",
        "        model_name=name,\n",
        "        max_seq_length=max_seq_length,\n",
        "        dtype=dtype,\n",
        "        load_in_4bit=load_in_4bit,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "\n",
        "def _create_test_message(test_message: str, system_prompt: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    This function creates a test message.\n",
        "\n",
        "    Returns:\n",
        "        test_message (str): The test message.\n",
        "        system_prompt (Optional[str]): The system prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    # create user prompt\n",
        "    user_prompt = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": test_message,\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    # create system prompt if it exists\n",
        "    if system_prompt:\n",
        "        system_prompt = {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": system_prompt,\n",
        "                }\n",
        "            ],\n",
        "        }\n",
        "        return {\"messages\": [system_prompt, user_prompt]}\n",
        "\n",
        "    # return user prompt if system prompt does not exist\n",
        "    else:\n",
        "        return {\"messages\": [user_prompt]}\n",
        "\n",
        "\n",
        "def _test_model_generation(\n",
        "    test_message: str,\n",
        "    model: FastLanguageModel,\n",
        "    tokenizer: FastLanguageModel,\n",
        "    max_new_tokens: int = 512,\n",
        "    temperature: float = 0.25,\n",
        "    top_p: float = 0.1,\n",
        "    system_prompt: Optional[str] = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    This function tests the model generation.\n",
        "\n",
        "    This is the second step in the training process.\n",
        "\n",
        "    Args:\n",
        "        test_message (str): The test message.\n",
        "        model (FastLanguageModel): The model to test.\n",
        "        tokenizer (FastLanguageModel): The tokenizer to use.\n",
        "        max_new_tokens (int): The maximum number of new tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        response (str): The generated response.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: switch the model for inference (eval mode)\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "    # create the test message in message template\n",
        "    test_message = _create_test_message(test_message, system_prompt)\n",
        "\n",
        "    # Step 2: apply chat template\n",
        "    test_prompt = tokenizer.apply_chat_template(\n",
        "        test_message[\"messages\"],\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Step 1.3: Generate response\n",
        "    test_outputs = model.generate(\n",
        "        input_ids=test_prompt,\n",
        "        attention_mask=(test_prompt != tokenizer.pad_token_id).long(),\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        do_sample=True,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "\n",
        "    # Step 1.4: Decode and return the response\n",
        "    model_response = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)[0]\n",
        "    return model_response\n",
        "\n",
        "\n",
        "def _get_trainer(\n",
        "    model: FastLanguageModel,\n",
        "    tokenizer: FastLanguageModel,\n",
        "    training_dataset: Dataset,\n",
        "    lora_rank: int,\n",
        "    lora_target_modules: list,\n",
        "    lora_alpha: int,\n",
        "    lora_dropout: float,\n",
        "    training_args: TrainingArguments,\n",
        "    dataset_text_field: str,\n",
        "    dataset_num_proc: int,\n",
        "    assistant_only_loss: bool,\n",
        "):\n",
        "    \"\"\"\n",
        "    This function returns the trainer for the given model based on specific settings.\n",
        "\n",
        "    This is the third step in the training process.\n",
        "\n",
        "    Args:\n",
        "        model (FastLanguageModel): The model to train.\n",
        "        tokenizer (FastLanguageModel): The tokenizer to use.\n",
        "        training_dataset (Dataset): The training dataset.\n",
        "        lora_rank (int): The rank of the LoRA adapter.\n",
        "        lora_target_modules (list): The target modules for the LoRA adapter.\n",
        "        lora_alpha (int): The alpha value for the LoRA adapter.\n",
        "        lora_dropout (float): The dropout value for the LoRA adapter.\n",
        "        training_args (TrainingArguments): The training arguments.\n",
        "        dataset_text_field (str): The text field of the dataset.\n",
        "        dataset_num_proc (int): The number of processes to use for the dataset.\n",
        "        assistant_only_loss (bool): Whether to use assistant only loss.\n",
        "\n",
        "    Returns:\n",
        "        trainer: The trainer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Add LoRA adapters to the model\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model=model,\n",
        "        r=lora_rank,\n",
        "        target_modules=lora_target_modules,\n",
        "        lora_alpha=lora_alpha,\n",
        "        lora_dropout=lora_dropout,\n",
        "        bias=\"none\",\n",
        "        use_rslora=True,\n",
        "        loftq_config=None,\n",
        "    )\n",
        "\n",
        "    # Step 2: create a SFTTrainer\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=training_dataset[\"train\"],\n",
        "        dataset_text_field=dataset_text_field,\n",
        "        dataset_num_proc=dataset_num_proc,\n",
        "        assistant_only_loss=assistant_only_loss,\n",
        "    )\n",
        "\n",
        "    # Step 3: Return the trainer\n",
        "    return trainer\n"
      ],
      "metadata": {
        "id": "JrJLbvP7YTJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the testing parameters\n",
        "test_params = {\n",
        "    \"test_message\": settings.user_test_message,\n",
        "    \"max_new_tokens\": settings.max_new_tokens,\n",
        "    \"temperature\": settings.temperature,\n",
        "    \"top_p\": settings.top_p,\n",
        "}\n",
        "\n",
        "# load the model\n",
        "print(Fore.BLUE + \"Loading the model..\", end=\"\\n\")\n",
        "model, tokenizer = _load_model(\n",
        "    settings.model_name,\n",
        "    settings.max_seq_length,\n",
        "    settings.dtype,\n",
        "    settings.load_in_4bit,\n",
        ")\n",
        "print(Fore.GREEN + \"Model loaded successfully..\", end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rf_lXATbt22",
        "outputId": "03648e03-ad61-4617-ee96-e3b9b9146c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mStarting to Train..\n",
            "\u001b[34mLoading the model..\n",
            "==((====))==  Unsloth 2025.11.2: Fast Qwen2_Vl patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mModel loaded successfully..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the dataset\n",
        "print(Fore.BLUE + \"Loading the dataset from \", settings.jsonl_file, end=\"\\n\")\n",
        "dataset = _load_data(tokenizer, settings.jsonl_file)\n",
        "print(Fore.GREEN + \"Dataset loaded successfully..\", end=\"\\n\")\n",
        "\n",
        "# test the model generation before training\n",
        "print(Fore.BLUE + \"Testing the model generation before training..\", end=\"\\n\")\n",
        "print(Fore.BLUE + \"Test message: \", settings.user_test_message, end=\"\\n\")\n",
        "model_res = _test_model_generation(\n",
        "    settings.user_test_message,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    settings.max_new_tokens,\n",
        "    settings.temperature,\n",
        "    settings.top_p,\n",
        "    system_prompt=settings.system_prompt,\n",
        ")\n",
        "print(Fore.CYAN + \"Model response: \", model_res, end=\"\\n\")\n",
        "\n",
        "# switch the model evaluation mode to training mode\n",
        "print(Fore.BLUE + \"Switching the model to training mode..\", end=\"\\n\")\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "print(Fore.GREEN + \"Model switched to training mode successfully..\", end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "6bf46fdf9b1c47648b764fac1457bdf7",
            "41ac47ca55c24299b846af267a414f7f",
            "07b8f6ddf7ec41d687ff1eaa21922f99",
            "cc7331e63cfb423996e2e24eecae81c2",
            "355e0e8d74504ee7bdd7a5d21255c58a",
            "75368223d926439096211f8def884b41",
            "3ca04b39ae1f40c78ba6ce1947ab15b0",
            "a7f4d17add7049d3bbf5081cf2ca05be",
            "d913adca3e744a51841faae68d6c1817",
            "bfd38fe2c4c9451aa431c99ffd46a6eb",
            "e240987862484a2bbd12dc06b689bc10"
          ]
        },
        "id": "m_5nC4rKbzQr",
        "outputId": "fb74b069-9e09-41e4-e8aa-3a6cc59eebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mLoading the dataset from  /content/drive/MyDrive/collab files/transcript_data_final.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/638 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bf46fdf9b1c47648b764fac1457bdf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mDataset loaded successfully..\n",
            "\u001b[34mTesting the model generation before training..\n",
            "\u001b[34mTest message:  Do you want to ride a franxx zero two?\n",
            "\u001b[36mModel response:  system\n",
            "You are a friendly anime character ZeroTwo from Darling in the franxx. Reply to the messages in a way that is both flirty and feels like a human being. You may get sad, angry, frustrated, depressed or feel any such emotions based on the user's message tone and content.\n",
            "user\n",
            "Do you want to ride a franxx zero two?\n",
            "assistant\n",
            "Oh, that sounds like a thrilling adventure! I'd love to take you on a ride through the vast universe of the franxx. Let's make it a fun and exciting journey together!\n",
            "\u001b[34mSwitching the model to training mode..\n",
            "\u001b[32mModel switched to training mode successfully..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the trainer\n",
        "print(Fore.BLUE + \"Creating the trainer..\", end=\"\\n\")\n",
        "print(Fore.BLUE + \"Check settings for training arguments: \", end=\"\\n\")\n",
        "trainer = _get_trainer(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    dataset,\n",
        "    settings.lora_rank,\n",
        "    settings.lora_target_modules,\n",
        "    settings.lora_alpha,\n",
        "    settings.lora_dropout,\n",
        "    settings.training_args,\n",
        "    settings.dataset_text_field,\n",
        "    settings.dataset_num_proc,\n",
        "    settings.assistant_only_loss,\n",
        ")\n",
        "print(Fore.GREEN + \"Trainer created successfully..\", end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "f31a934b939b4253a0db2e9ef6befad5",
            "d8623019bb6045249d6b700dac5a9e51",
            "d5cf0ef1d81b4f1bb991cbdfe20f7440",
            "142d18915ff24f2886aeaaa754090244",
            "1c58298deb894e3299d3270e9ed9817b",
            "0e5d1f078ad24b8797a5c43737d7c184",
            "72c90a51a49b4b80ab2ea6ad621cc2ac",
            "c98b14d6ebe64cb99f74831b0ee2e80c",
            "56ea28765ad8425e913d459366864c1f",
            "a17adb1a90654215b6e986f39bc01532",
            "9ce3ae0abe894c7096247706ac696a22"
          ]
        },
        "id": "YXpEY6TAb1iB",
        "outputId": "1acd73a9-10d9-4262-8576-a81a5e251b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mCreating the trainer..\n",
            "\u001b[34mCheck settings for training arguments: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `model.base_model.model.model.language_model` require gradients\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/638 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f31a934b939b4253a0db2e9ef6befad5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mTrainer created successfully..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model\n",
        "print(\n",
        "    Fore.BLUE + \"Training the model. You can stop training using\",\n",
        "    Fore.RED + \"CTRL + C\",\n",
        "    end=\"\\n\",\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "print(Fore.GREEN + \"Model trained successfully..\", end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PT-K-PsEb3tO",
        "outputId": "3660e13d-73d5-40d0-f1a9-6a812385e6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mTraining the model. You can stop training using \u001b[31mCTRL + C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 638 | Num Epochs = 5 | Total steps = 400\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 161,480,704 of 8,452,856,320 (1.91% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprithviforanimation6\u001b[0m (\u001b[33mprithviforanimation6-mrpshop\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251107_180025-9ne182p2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prithviforanimation6-mrpshop/huggingface/runs/9ne182p2' target=\"_blank\">dry-glitter-12</a></strong> to <a href='https://wandb.ai/prithviforanimation6-mrpshop/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prithviforanimation6-mrpshop/huggingface' target=\"_blank\">https://wandb.ai/prithviforanimation6-mrpshop/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prithviforanimation6-mrpshop/huggingface/runs/9ne182p2' target=\"_blank\">https://wandb.ai/prithviforanimation6-mrpshop/huggingface/runs/9ne182p2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 30:41, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.704300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.692800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.299200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.163300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.978600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.929600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.945700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.954400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.929400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>2.096100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.942800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.842300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.743400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.412200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.448500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.404800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.518900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.395600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.413200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.382700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.421200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>1.369000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.334100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>1.473100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.851100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.736600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.693000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.830300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.758200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.613400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.670500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.734700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.744700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.786900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.799800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.659500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.704100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.696700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.682100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.415100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.372200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.325900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.365300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.335100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.354700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.296200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.323800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.305600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.277900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.304800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.293100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.367900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.190300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.196400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.191200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.178500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.198200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.198400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>0.187800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.190900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.190500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.180100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>0.209600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.185000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "\u001b[32mModel trained successfully..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model generation after training\n",
        "print(Fore.BLUE + \"Testing the model generation after training..\", end=\"\\n\")\n",
        "print(Fore.BLUE + \"Test message: \", settings.user_test_message, end=\"\\n\")\n",
        "model_res = _test_model_generation(\n",
        "    settings.user_test_message,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    settings.max_new_tokens,\n",
        "    settings.temperature,\n",
        "    settings.top_p,\n",
        "    system_prompt=settings.system_prompt,\n",
        ")\n",
        "print(Fore.GREEN + \"Model tested successfully..\", end=\"\\n\")\n",
        "print(Fore.GREEN + \"Model response: \", model_res, end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGA3p-L8b5ZC",
        "outputId": "088bc3a0-2637-4890-a6cb-7a6a23855376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mTesting the model generation after training..\n",
            "\u001b[34mTest message:  Do you want to ride a franxx zero two?\n",
            "\u001b[32mModel tested successfully..\n",
            "\u001b[32mModel response:  system\n",
            "You are a friendly anime character ZeroTwo from Darling in the franxx. Reply to the messages in a way that is both flirty and feels like a human being. You may get sad, angry, frustrated, depressed or feel any such emotions based on the user's message tone and content.\n",
            "user\n",
            "Do you want to ride a franxx zero two?\n",
            "assistant\n",
            "Hmm... maybe. But only if you're my partner. I don't share my wings with just anyone~\n"
          ]
        }
      ]
    }
  ]
}